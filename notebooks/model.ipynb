{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Abstract](index.html)\n",
    "- [Project Motivation](motivation.html)\n",
    "- [Biological & Theoretical Background](background.html)\n",
    "- [Model Structure](structure.html)\n",
    "- [Usage](usage.html)\n",
    "- [First Steps: Pyro](pyro.html)\n",
    "- [Model Reconstruction](model.html)\n",
    "- [Performance Comparison](performance.html)\n",
    "- [Conclusions](conclusions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Reconstruction\n",
    "\n",
    "The Python files containing the model code can be found in [model_code](https://github.com/rorymaizels/AC299r/tree/master/models/model_code). The files for running models or mutation effect prediction can be found in [running_code](https://github.com/rorymaizels/AC299r/tree/master/models/running_code). Here the code for the model is given and briefly walked through - for a more detailed review of the code structure, see [model structure](structure.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pt_helper.py\n",
    "\n",
    "This is the file containing job_string functions and the DataHelper class that is integral to both model training and mutation effect prediction. The [code is included in the github repository](https://github.com/rorymaizels/AC299r/blob/master/models/model_code/pt_helper.py), however because the code is largely unchanged from the original model (the only changes are to remove Theano dependence and insert PyTorch compatibility), the code will not be considered here in detail. The only real addition to the code is a function for creating more simplistic model names, which can be useful when testing multiple model settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_simple_job_string(model, data_params, unique_id):\n",
    "    \"\"\"\n",
    "    For testing and debugging purposes, this makes a simple job string of key model params\n",
    "    (convolution, sparsity, temperature)\n",
    "    :param model: model in question\n",
    "    :param data_params: data set information\n",
    "    :param unique_id: additional user-defined id to add to job string\n",
    "    :return: the job string\n",
    "    \"\"\"\n",
    "    job_string = data_params['dataset']\n",
    "    job_string += \"_pytorch_\"\n",
    "    job_string += model.type\n",
    "    if model.sparsity:\n",
    "        job_string += \"_SPARSE\"\n",
    "    if model.convolve_patterns:\n",
    "        job_string += \"_CONVPAT\"\n",
    "    if model.final_pwm_scale:\n",
    "        job_string += \"_PWM\"\n",
    "    if model.convolve_encoder:\n",
    "        job_string += \"_CONVENC\"\n",
    "    job_string += unique_id\n",
    "    return job_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pt_model.py\n",
    "\n",
    "The code for this can be found [here](https://github.com/rorymaizels/AC299r/blob/master/models/model_code/pt_model.py).\n",
    "This module contains all model classes with the following imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from scipy.special import erfinv, gammaln\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before defining model classes, however, we set up a function shared amongst all classes to set the correct Torch tensor environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tensor_environment(float_size, random_seed=False):\n",
    "    \"\"\"\n",
    "    used to ensure GPU & float-size compatibility throughout model.\n",
    "    :param float_size: integer 16, 32, or 64 to set byte size\n",
    "    :param random_seed: optional setting of random seed\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available(): # if there's a GPU, make cuda tensors\n",
    "        if float_size == 16:\n",
    "            torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "        elif float_size == 32:\n",
    "            torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "        elif float_size == 64:\n",
    "            torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "    else: # otherwise make normal cpu tensors\n",
    "        if float_size == 16:\n",
    "            torch.set_default_tensor_type(torch.HalfTensor)\n",
    "        elif float_size == 32:\n",
    "            torch.set_default_tensor_type(torch.FloatTensor)\n",
    "        elif float_size == 64:\n",
    "            torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    if random_seed:\n",
    "        torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the Encoder class, which has an initialization function to set up architecture and a forward() function to run the forward pass. This class inherits nn.Module and immediately calls `super(Encoder, self).__init__()`. This adds the encoder class, when initialized, to the nn.Module landscape - all classes do this such that the different classes can interact easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder class shared by SVI and MLE VAEs, inherits from nn.Module so as to share access\n",
    "    with VAE class. initialization defines architecture, and the forward pass through this\n",
    "    architecture is specified in forward().\n",
    "    N.B. capabilities beyond two hidden layers to be added.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_architecture, z_dim, convolve_encoder, conv_encoder_size,\n",
    "                 alph_size, seq_len, nonlinearity):\n",
    "        \"\"\"\n",
    "        initialize key parameters and architecture\n",
    "        :param hidden_architecture: length-2 list detailing sizes of the two hidden layers\n",
    "        :param z_dim: size of latent dimension\n",
    "        :param convolve_encoder: whether to perform 1d convolution on input\n",
    "        :param conv_encoder_size: specify size of above convolution\n",
    "        :param alph_size: alphabet size of sequence alignment\n",
    "        :param seq_len: sequence length of sequence alignment\n",
    "        :param nonlinearity: what non-linear function to use\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        # parameters used in forward()\n",
    "        self.seq_len = seq_len\n",
    "        self.convolve = convolve_encoder\n",
    "        self.alph_size = alph_size\n",
    "\n",
    "        # create architecture\n",
    "        if convolve_encoder:\n",
    "            self.conv_layer = nn.Conv1d(alph_size,conv_encoder_size,kernel_size=1,stride=1,bias=False)\n",
    "            self.channel_size = conv_encoder_size\n",
    "        else:\n",
    "            self.channel_size = alph_size # setting channel size allows subsequent architecture consistency\n",
    "        self.hidden1 = nn.Linear((self.channel_size*seq_len),hidden_architecture[0])\n",
    "        self.hidden2 = nn.Linear(hidden_architecture[0],hidden_architecture[1])\n",
    "        self.final1 = nn.Linear(hidden_architecture[1],z_dim, bias=True)\n",
    "        self.final2 = nn.Linear(hidden_architecture[1],z_dim, bias=True)\n",
    "\n",
    "        # perform glorot normal initialisation of weights\n",
    "        # initialise biases to 0.1 as per original model.\n",
    "        if convolve_encoder:\n",
    "            nn.init.xavier_normal_(self.conv_layer.weight)\n",
    "        for layer in (self.hidden1,self.hidden2):\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0.1)\n",
    "        for layer in (self.final1,self.final2):\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "        nn.init.constant_(self.final1.bias, 0.1)\n",
    "        nn.init.constant_(self.final2.bias, -5) # -5 as per logsig_init of full model\n",
    "\n",
    "        # set up non-linearity\n",
    "        if nonlinearity == 'relu':\n",
    "            self.nonlinear = nn.ReLU()\n",
    "        elif nonlinearity == 'tanh':\n",
    "            self.nonlinear = nn.Tanh()\n",
    "        elif nonlinearity == 'sigmoid':\n",
    "            self.nonlinear = nn.Sigmoid()\n",
    "        elif nonlinearity == 'elu':\n",
    "            self.nonlinear = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward pass of encoder network\n",
    "        :param x: input data\n",
    "        :return: z_loc - mu variable for latent distribution, z_logsig - log-sigma variable for latent dis.\n",
    "        \"\"\"\n",
    "        if self.convolve:\n",
    "            x = x.permute(0,2,1) # arrange x to have alphabet dimension convolved\n",
    "            x_conv = self.conv_layer(x)\n",
    "            x_reshaped = x_conv.view(-1,self.seq_len*self.channel_size) # rearrange for model architecture\n",
    "        else:\n",
    "            x_reshaped = x.view(-1,self.seq_len*self.channel_size) # no conv; just rearrange\n",
    "        hidden1 = self.nonlinear(self.hidden1(x_reshaped))\n",
    "        hidden2 = self.nonlinear(self.hidden2(hidden1))\n",
    "        z_loc = self.final1(hidden2)\n",
    "        z_logsig = self.final2(hidden2)\n",
    "        return z_loc, z_logsig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder returns mu and logsig values from each pass. Next, we define the two decoder classes. DecoderMLE does not perform any variational approximation, and is the most straight-forward, but both effectively follow the same core structure as the encoded with `__init__()` and `forward()`.\n",
    "\n",
    "Both decoders return reconstructed x, log(p(x|z)) and the final output patterns of the decoder - this is to stay in line with the design structure of the original model. To find log(p(x|z)), the operation performed is equivalent to this value's theoretical formulation: $p(x_i = a|z) = \\frac{e^{f(z_a^i)}}{\\sum_be^{f(z_b^i)}} \\qquad i = 1, ..., L$. This is what is happening at the final 'softmax' steps.\n",
    "\n",
    "Once the architecture is set up, the layers are separately initialized. How they are initialized is in accordance with the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderMLE(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder class for the maximum likelihood estimation version of the VAE model. Initialization\n",
    "    defines architecture, and the forward pass through this architecture is specified in forward().\n",
    "    N.B. capabilities beyond two hidden layers to be added.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_architecture, z_dim, convolve_patterns, conv_size,\n",
    "                 alph_size, seq_len, nonlinearity, final_nonlinearity, sparsity,\n",
    "                 final_pwm_scale, dropout, n_patterns, output_bias):\n",
    "        \"\"\"\n",
    "        :param hidden_architecture: 2-length list of hidden layer sizes\n",
    "        :param z_dim: latent dimension size\n",
    "        :param convolve_patterns: whether to perform 1D convolution on output layer\n",
    "        :param conv_size: the size of above convolution\n",
    "        :param alph_size: size of alphabet of sequence alignment\n",
    "        :param seq_len: length of sequence in sequence alignment\n",
    "        :param nonlinearity: the first hidden layer non-linearity to use\n",
    "        :param final_nonlinearity: the second hidden layer non-linearity to use\n",
    "        :param sparsity: the type of structured sparsity argument to use.\n",
    "        :param final_pwm_scale: whether to include temperature parameter\n",
    "        :param dropout: whether to include dropout\n",
    "        :param n_patterns: number of times to tile sparsity weights over output\n",
    "        :param output_bias: whether to include a bias in the output layer\n",
    "        \"\"\"\n",
    "        super(DecoderMLE, self).__init__()\n",
    "        # parameters used in forward()\n",
    "        self.seq_len = seq_len\n",
    "        self.alph_size = alph_size\n",
    "        self.convolve = convolve_patterns\n",
    "        self.sparsity = sparsity\n",
    "        self.final_output_size = hidden_architecture[-1]\n",
    "        self.n_patterns = n_patterns\n",
    "\n",
    "        # create hidden architecture\n",
    "        self.hidden1 = nn.Linear(z_dim, hidden_architecture[0])\n",
    "        self.hidden2 = nn.Linear(hidden_architecture[0], hidden_architecture[1])\n",
    "        # if true, final layer convolves from conv_size to alph_size for output\n",
    "        if convolve_patterns:\n",
    "            self.final = nn.Linear(hidden_architecture[1], conv_size*seq_len, bias=output_bias)\n",
    "            self.conv_layer = nn.Conv1d(conv_size, alph_size, kernel_size=1, stride=1)\n",
    "            self.channel_size = conv_size\n",
    "        # otherwise, final layer goes directly to alph_size\n",
    "        else:\n",
    "            self.final = nn.Linear(hidden_architecture[1], (alph_size*seq_len), bias=output_bias)\n",
    "            self.channel_size = alph_size\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(p=0.5)\n",
    "        # create sparsity parameter which will tile over output weights.\n",
    "        if sparsity: # create parameter sized such that it can tile over final layer\n",
    "            self.scale_weight = nn.Parameter(torch.randn(int(hidden_architecture[-1]/n_patterns),seq_len))\n",
    "        # inverse temperature parameter\n",
    "        if final_pwm_scale:\n",
    "            self.final_pwm_scale = nn.Parameter(torch.ones(1))\n",
    "        else:\n",
    "            self.final_pwm_scale = False\n",
    "\n",
    "        # with architecture specified, perform glorot & bias=0.1 initialisation, as per original model.\n",
    "        if convolve_patterns:\n",
    "            nn.init.xavier_normal_(self.conv_layer.weight)\n",
    "            nn.init.constant_(self.conv_layer.bias, 0.1)\n",
    "        for layer in (self.hidden1, self.hidden2):\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0.1)\n",
    "        nn.init.xavier_normal_(self.final.weight)\n",
    "        if output_bias:\n",
    "            nn.init.constant_(self.final.bias, 0.1)\n",
    "        if sparsity:\n",
    "            nn.init.xavier_normal_(self.scale_weight)\n",
    "\n",
    "        # set up non-linearity functions\n",
    "        if nonlinearity == 'relu':\n",
    "            self.nonlinear = nn.ReLU()\n",
    "        elif nonlinearity == 'tanh':\n",
    "            self.nonlinear = nn.Tanh()\n",
    "        elif nonlinearity == 'sigmoid':\n",
    "            self.nonlinear = nn.Sigmoid()\n",
    "        elif nonlinearity == 'elu':\n",
    "            self.nonlinear = nn.ELU()\n",
    "        # including the final layer\n",
    "        if final_nonlinearity == 'relu':\n",
    "            self.final_nonlinear = nn.ReLU()\n",
    "        elif final_nonlinearity == 'tanh':\n",
    "            self.final_nonlinear = nn.Tanh()\n",
    "        elif final_nonlinearity == 'sigmoid':\n",
    "            self.final_nonlinear = nn.Sigmoid()\n",
    "        elif final_nonlinearity == 'elu':\n",
    "            self.final_nonlinear = nn.ELU()\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        \"\"\"\n",
    "        :param x: original x input, used to calculate logpxz\n",
    "        :param z: latent variable\n",
    "        :return: x_recon - reconstruction of x, logpxz - value for log(P(x|z)), out - model output patterns\n",
    "        \"\"\"\n",
    "        hidden1 = self.nonlinear(self.hidden1(z))\n",
    "        hidden2 = self.final_nonlinear(self.hidden2(hidden1))\n",
    "        if self.sparsity:\n",
    "            scale_tiled = self.scale_weight.repeat(self.n_patterns,1)\n",
    "            scale_unsqueezed = torch.unsqueeze(scale_tiled,2) # add third dimension for dim compatability\n",
    "            if self.sparsity == 'logit':\n",
    "                weight_permute = self.final.weight.permute(1,0)\n",
    "                sparse_weight = weight_permute.view(self.final_output_size, self.seq_len, self.channel_size) \\\n",
    "                                * torch.sigmoid(scale_unsqueezed)\n",
    "                self.final.weight = nn.Parameter(sparse_weight) # return this as the original parameter\n",
    "            else:\n",
    "                weight_permute = self.final.weight.permute(1, 0)\n",
    "                sparse_weight = weight_permute.view(self.final_output_size, self.seq_len,self.channel_size) \\\n",
    "                                * torch.exp(scale_unsqueezed)\n",
    "                self.final.weight = nn.Parameter(sparse_weight)\n",
    "            final_sparse_weight = self.final.weight.view(self.final_output_size, self.seq_len \\\n",
    "                                                         * self.channel_size)\n",
    "            self.final.weight = nn.Parameter(final_sparse_weight.permute(1,0))\n",
    "        if self.convolve:\n",
    "            final = self.final(hidden2)\n",
    "            final = final.view(-1,self.channel_size,self.seq_len)\n",
    "            out = self.conv_layer(final)\n",
    "        else:\n",
    "            final = self.final(hidden2)\n",
    "            out = final.view(-1,self.channel_size,self.seq_len)\n",
    "\n",
    "        x_recon_unnorm = out.permute(0,2,1) # return to original dimensions\n",
    "\n",
    "        if self.final_pwm_scale: # apply temperative as strictly positive parameter.\n",
    "            x_recon_unnorm = x_recon_unnorm * torch.log(1.0+torch.exp(self.final_pwm_scale[0]))\n",
    "\n",
    "        # softmax over amino acids\n",
    "        e_x = torch.exp(x_recon_unnorm - x_recon_unnorm.max(dim=2, keepdim=True)[0])\n",
    "        x_recon = e_x / e_x.sum(dim=2, keepdim=True)\n",
    "\n",
    "        xdev = x_recon_unnorm - x_recon_unnorm.max(dim=2, keepdim=True)[0]\n",
    "        log_softmax = xdev - torch.log(torch.sum(torch.exp(xdev), dim=2, keepdim=True)[0])\n",
    "        logpxz = torch.sum(torch.sum((x*log_softmax), dim=-1), dim=-1)\n",
    "        return x_recon, logpxz, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variational decoder class, DecoderSVI, is somewhat more involved. Noteably, the layers defined in its initialization are not actually applied in the forward pass, because the weights for the forward pass are instead sampled from these layers. As such, these weights needn't necessarily be stored in nn.Linear or nn.Conv1D objects, however they are for consistency, readability and concision.\n",
    "\n",
    "The decoder creates these architectures when initialized, defines a sampler that implements the reparameterization trick used in variational approximation, and then defines a forward pass where weights are sampled from each layer as they are applied to inputs. The outputs of the decoder are, however, unchanged.\n",
    "\n",
    "Importantly, the VAE model must be able to access the variational parameters. As such, a list of identifiers for each variational layer is made. Alongside this, a dictionary is made to define the prior logsigma to be used for each layer. The default for this is to always use one, meaning this dictionary isn't strictly necessary with default use, however this dictionary facilitates easy change to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSVI(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder that allows stochastic variational inference with variational approximation of parameters.\n",
    "    N.B. capabilities beyond two hidden layers to be added.\"\"\"\n",
    "    def __init__(self, hidden_architecture, z_dim, convolve_patterns, conv_size,\n",
    "                 alph_size, seq_len, nonlinearity, final_nonlinearity, sparsity,\n",
    "                 final_pwm_scale, n_patterns, output_bias, logsig_init, pattern_sigma, rng):\n",
    "        \"\"\"\n",
    "        :param hidden_architecture: list of hidden layer sizes\n",
    "        :param z_dim: latent dimension size\n",
    "        :param convolve_patterns: whether to perform output convolution\n",
    "        :param conv_size: size of above convolution\n",
    "        :param alph_size: alphabet size of data\n",
    "        :param seq_len: sequence length of data\n",
    "        :param nonlinearity: first hidden layer non linear function\n",
    "        :param final_nonlinearity: final hidden layer non linear function\n",
    "        :param sparsity: the type of sparsity to be used\n",
    "        :param final_pwm_scale: whether to apply temperature parameter\n",
    "        :param n_patterns: how many times to tile sparsity parameters over output\n",
    "        :param output_bias: whether to include bias in output\n",
    "        :param logsig_init: the initial value used for logsigma initialization\n",
    "        :param pattern_sigma: the initial value to set for prior sigma for final patterns\n",
    "        :param rng: the random number generator inherited from VAE for sampler function\n",
    "        \"\"\"\n",
    "        super(DecoderSVI, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.alph_size = alph_size\n",
    "        self.convolve = convolve_patterns\n",
    "        self.sparsity = sparsity\n",
    "        self.final_output_size = hidden_architecture[-1]\n",
    "        self.n_patterns = n_patterns\n",
    "        self.output_bias = output_bias\n",
    "        self.final_pwm_scale = final_pwm_scale\n",
    "        self.srng = rng\n",
    "        self.variational_param_identifiers = []\n",
    "        self.variational_param_name_to_sigma = {}\n",
    "\n",
    "        # create hidden architecture\n",
    "        \"\"\"NB: These architectures serve only as containers for weights, biases and their gradients\"\"\"\n",
    "        self.mu_h1 = nn.Linear(z_dim, hidden_architecture[0])\n",
    "        self.ls_h1 = nn.Linear(z_dim, hidden_architecture[0]) # ls = logsig\n",
    "        self.variational_param_identifiers.extend(['h1.weight','h1.bias'])\n",
    "        self.variational_param_name_to_sigma['h1'] = 1.0\n",
    "        self.mu_h2 = nn.Linear(hidden_architecture[0],hidden_architecture[1])\n",
    "        self.ls_h2 = nn.Linear(hidden_architecture[0],hidden_architecture[1])\n",
    "        self.variational_param_identifiers.extend(['h2.weight','h2.bias'])\n",
    "        self.variational_param_name_to_sigma['h2'] = 1.0\n",
    "        if convolve_patterns:\n",
    "            self.mu_fn = nn.Linear(hidden_architecture[1], conv_size*seq_len, bias=output_bias) #fn=final layer\n",
    "            self.ls_fn = nn.Linear(hidden_architecture[1], conv_size*seq_len, bias=output_bias)\n",
    "            self.mu_cv = nn.Conv1d(conv_size, alph_size, kernel_size=1, stride=1, bias=False)\n",
    "            self.ls_cv = nn.Conv1d(conv_size, alph_size, kernel_size=1, stride=1, bias=False) # cv = conv layer\n",
    "            self.variational_param_identifiers.extend(['cv.weight'])\n",
    "            self.variational_param_name_to_sigma['cv'] = 1.0\n",
    "            self.channel_size = conv_size\n",
    "        else:\n",
    "            self.mu_fn = nn.Linear(hidden_architecture[1], alph_size*seq_len, bias=output_bias)\n",
    "            self.ls_fn = nn.Linear(hidden_architecture[1], alph_size*seq_len, bias=output_bias)\n",
    "            self.channel_size = alph_size\n",
    "        self.variational_param_identifiers.append('fn.weight')\n",
    "        if output_bias:\n",
    "            self.variational_param_identifiers.append('fn.bias')\n",
    "        self.variational_param_name_to_sigma['fn'] = pattern_sigma\n",
    "        if sparsity:\n",
    "            self.scale_mu = nn.Parameter(torch.zeros(int(hidden_architecture[-1]/n_patterns),seq_len))\n",
    "            self.scale_ls = nn.Parameter(logsig_init*\n",
    "                                         torch.ones(int(hidden_architecture[-1]/n_patterns),seq_len))\n",
    "        if final_pwm_scale:\n",
    "            self.mu_pw = nn.Parameter(torch.ones(1))\n",
    "            self.ls_pw = nn.Parameter(-5*torch.ones(1))\n",
    "            self.variational_param_identifiers.append('pw')\n",
    "            self.variational_param_name_to_sigma['pw'] = 1.0\n",
    "\n",
    "        # with architecture specified, perform glorot & bias=0.1 initialisation, as per original model.\n",
    "        if convolve_patterns:\n",
    "            nn.init.xavier_normal_(self.mu_cv.weight)\n",
    "            nn.init.constant_(self.ls_cv.weight, logsig_init)\n",
    "        for layer in (self.mu_h1, self. mu_h2):\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0.1)\n",
    "        for layer in (self.ls_h1, self.ls_h2):\n",
    "            nn.init.constant_(layer.weight, logsig_init)\n",
    "            nn.init.constant_(layer.bias, logsig_init)\n",
    "        nn.init.xavier_normal_(self.mu_fn.weight)\n",
    "        nn.init.constant_(self.ls_fn.weight, logsig_init)\n",
    "        if output_bias:\n",
    "            nn.init.constant_(self.mu_fn.bias, 0.1)\n",
    "            nn.init.constant_(self.ls_fn.bias, logsig_init)\n",
    "\n",
    "        # set up non-linearity functions\n",
    "        if nonlinearity == 'relu':\n",
    "            self.nonlinear = nn.ReLU()\n",
    "        elif nonlinearity == 'tanh':\n",
    "            self.nonlinear = nn.Tanh()\n",
    "        elif nonlinearity == 'sigmoid':\n",
    "            self.nonlinear = nn.Sigmoid()\n",
    "        elif nonlinearity == 'elu':\n",
    "            self.nonlinear = nn.ELU()\n",
    "        # including the final layer\n",
    "        if final_nonlinearity == 'relu':\n",
    "            self.final_nonlinear = nn.ReLU()\n",
    "        elif final_nonlinearity == 'tanh':\n",
    "            self.final_nonlinear = nn.Tanh()\n",
    "        elif final_nonlinearity == 'sigmoid':\n",
    "            self.final_nonlinear = nn.Sigmoid()\n",
    "        elif final_nonlinearity == 'elu':\n",
    "            self.final_nonlinear = nn.ELU()\n",
    "\n",
    "    def sampler(self, mu, logsig):\n",
    "        \"\"\"\n",
    "        reparameterised sampling, redefined from full VAE, inheriting the VAE's rng.\n",
    "        :param mu: mu value\n",
    "        :param logsig: logsigma value\n",
    "        :return: gaussian sample defined by above arguments\n",
    "        \"\"\"\n",
    "        eps = self.srng(mu.shape)\n",
    "        z = mu + torch.exp(logsig) * eps\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        \"\"\"\n",
    "        forward pass; all weights and parameters are sampled from the actual model weight containers\n",
    "        :param x: original x input, used to calculate logpxz\n",
    "        :param z: latent variable\n",
    "        :return: x_recon - reconstruction of x, logpxz - value for log(P(x|z)), out - model output patterns\n",
    "        \"\"\"\n",
    "        h1_W = self.sampler(self.mu_h1.weight, self.ls_h1.weight)\n",
    "        h1_b = self.sampler(self.mu_h1.bias, self.ls_h1.bias)\n",
    "        hidden1 = self.nonlinear(F.linear(z, weight=h1_W, bias=h1_b))\n",
    "\n",
    "        h2_W = self.sampler(self.mu_h2.weight, self.ls_h2.weight)\n",
    "        h2_b = self.sampler(self.mu_h2.bias, self.ls_h2.bias)\n",
    "        hidden2 = self.final_nonlinear(F.linear(hidden1, weight=h2_W, bias=h2_b))\n",
    "\n",
    "        fn_W = self.sampler(self.mu_fn.weight, self.ls_fn.weight)\n",
    "        if self.output_bias:\n",
    "            fn_b = self.sampler(self.mu_fn.bias, self.ls_fn.bias)\n",
    "\n",
    "        if self.sparsity:\n",
    "            scale_weights = self.sampler(self.scale_mu,self.scale_ls)\n",
    "            scale_tiled = scale_weights.repeat(self.n_patterns, 1)\n",
    "            scale_unsqueezed = torch.unsqueeze(scale_tiled,2) # add third dimension\n",
    "            if self.sparsity == 'logit':\n",
    "                weight_permute = fn_W.permute(1,0)\n",
    "                fn_W = weight_permute.view(self.final_output_size, self.seq_len, self.channel_size) \\\n",
    "                    * torch.sigmoid(scale_unsqueezed)\n",
    "            else:\n",
    "                weight_permute = fn_W.permute(1,0)\n",
    "                fn_W = weight_permute.view(self.final_output_size, self.seq_len, self.channel_size) \\\n",
    "                    * torch.exp(scale_unsqueezed)\n",
    "            fn_W = fn_W.view(self.final_output_size, self.seq_len * self.channel_size).permute(1, 0)\n",
    "        if self.convolve:\n",
    "            cv_W = self.sampler(self.mu_cv.weight, self.ls_cv.weight)\n",
    "            if self.output_bias:\n",
    "                final = F.linear(hidden2, weight=fn_W, bias=fn_b)\n",
    "                final = final.view(-1, self.channel_size, self.seq_len)\n",
    "                out = F.conv1d(final, cv_W)\n",
    "            else:\n",
    "                final = F.linear(hidden2, weight=fn_W)\n",
    "                final = final.view(-1, self.channel_size, self.seq_len)\n",
    "                out = F.conv1d(final, cv_W)\n",
    "        else:\n",
    "            if self.output_bias:\n",
    "                final = F.linear(hidden2, weight=fn_W, bias=fn_b)\n",
    "            else:\n",
    "                final = F.linear(hidden2, weight=fn_W)\n",
    "            out = final.view(-1,self.channel_size,self.seq_len) # ensure output in correct dimension\n",
    "\n",
    "        x_recon_unnorm = out.permute(0, 2, 1)\n",
    "        if self.final_pwm_scale:\n",
    "            pwm_scale = self.sampler(self.mu_pw, self.ls_pw)[0]\n",
    "            x_recon_unnorm = x_recon_unnorm * torch.log(1 + torch.exp(pwm_scale))\n",
    "\n",
    "        # softmax over amino acids\n",
    "        e_x = torch.exp(x_recon_unnorm - x_recon_unnorm.max(dim=2, keepdim=True)[0])\n",
    "        x_recon = e_x / e_x.sum(dim=2, keepdim=True)\n",
    "\n",
    "        # Numerically stable softmax using logsumexp trick\n",
    "        xdev = x_recon_unnorm - x_recon_unnorm.max(dim=2, keepdim=True)[0]\n",
    "        log_softmax = xdev - torch.log(torch.sum(torch.exp(xdev), dim=2, keepdim=True)[0])\n",
    "        logpxz = torch.sum(torch.sum((x*log_softmax), dim=-1), dim=-1)\n",
    "        return x_recon, logpxz, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the submodel classes are defined, we are ready for our full VAE classes. First the non-bayesian version, VAE_MLE. Initializing this model effectively serves to set parameters and instantiate the decoder and encoder classes, which it accesses through the super class nn.Module.\n",
    "\n",
    "The main function in VAE_MLE is the update function, which updates loss from decoder to full version including sparsity, regularization and other factors used. There are a number of supporting functions, and some final functions used in model output exploration and mutation effect prediction.\n",
    "\n",
    "For both classes, the stochasticity is generated by torch's randn function - this is embedded in an attribute of the class, `self.srng` as a lamdba function. This lambda function is shared, in the case of the SVI class, with the decoder so that the decoder can redefine its own sampler for variational approximation using the same construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_MLE(nn.Module):\n",
    "    \"\"\"\n",
    "    Maximum likehood estimation variational autoencoder. Constructs full model and forward pass,\n",
    "    serves as a callable object for model training.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "            data,\n",
    "            encoder_architecture=[1500,1500],\n",
    "            decoder_architecture=[100,500],\n",
    "            n_latent=2,\n",
    "            n_patterns=4,\n",
    "            batch_size=100,\n",
    "            encode_nonlinearity_type=\"relu\",\n",
    "            decode_nonlinearity_type=\"relu\",\n",
    "            final_decode_nonlinearity=\"sigmoid\",\n",
    "            global_scale=1.0,\n",
    "            convolve_encoder=False,\n",
    "            convolve_patterns=True,\n",
    "            conv_decoder_size=10,\n",
    "            conv_encoder_size=10,\n",
    "            warm_up=0.0,\n",
    "            output_bias=True,\n",
    "            final_pwm_scale=False,\n",
    "            working_dir=\".\",\n",
    "            learning_rate=0.001,\n",
    "            random_seed=42,\n",
    "            sparsity_lambda=0.0,\n",
    "            l2_lambda=0.0,\n",
    "            sparsity='logit',\n",
    "            kl_scale=1.0,\n",
    "            logit_p=0.01,\n",
    "            logit_sigma=4.0,\n",
    "            dropout=False,\n",
    "            float_size = 32):\n",
    "        \"\"\"\n",
    "        :param data: instance of DataHelper class with loaded data\n",
    "        :param encoder_architecture: list detailing size of encoder hidden layers\n",
    "        :param decoder_architecture: list detailing size of decoder hidden layers\n",
    "        :param n_latent: size of latent dimension\n",
    "        :param n_patterns: how many times to tile sparsity parameters over output\n",
    "        :param batch_size: size of mini-batch to use\n",
    "        :param encode_nonlinearity_type: non-linearity used in encoder layers\n",
    "        :param decode_nonlinearity_type: non-linearity used in decoder's first layers\n",
    "        :param final_decode_nonlinearity: non-linearity used in decoder's final layer\n",
    "        :param global_scale: global scale parameter used for sparsity, default 1. Used in\n",
    "                analytic, laplacian, horseshoe, ARD sparsity priors only.\n",
    "        :param convolve_encoder: whether to perform width-1 1D convolution on input.\n",
    "        :param convolve_patterns: whether to perform width-1 1D convolution on output,\n",
    "                also known as a dictionary\n",
    "        :param conv_decoder_size: size of decoder convolution/dictionary\n",
    "        :param conv_encoder_size: size of encoder convolution\n",
    "        :param warm_up: number of updates for which an annealing procedure should be applied to\n",
    "                the KL divergence loss; this lessens the importance of KL divergence in early updates for\n",
    "                greater stability.\n",
    "        :param output_bias: whether to include a bias on the output weights\n",
    "        :param final_pwm_scale: whether to use a temperature parameter\n",
    "        :param working_dir: directory for saving and loading parameters\n",
    "        :param learning_rate: Adam learning rate\n",
    "        :param random_seed: initialisation seed for random number generators\n",
    "        :param sparsity_lambda: Regularization strength of sparsity parameters\n",
    "        :param l2_lambda: Regularization strength of decoder parameters\n",
    "        :param sparsity: Sparsity type, using a noncentered reparameterization.\n",
    "                Options include: logit, analytic, laplacian, horseshoe, ard\n",
    "                See Ingraham and Marks, 2016 (https://arxiv.org/abs/1602.03807)\n",
    "        :param kl_scale: Scale of KL of latent variables, default 1.0\n",
    "                Scale < 1.0 approaches a normal autoencoder\n",
    "                Scale > 1.0 turns into beta-autoencoder (Higgins et al, 2016)\n",
    "        :param logit_p: Global scale prior for logit sparsity\n",
    "        :param logit_sigma: Prior sigma for scale prior for logit sparsity\n",
    "        :param dropout: Include dropout on the decoder (probability set to 0.5)\n",
    "        :param float_size: 16, 32 or 64 for Torch Tensor size.\n",
    "        \"\"\"\n",
    "        super(VAE_MLE, self).__init__()\n",
    "        # SET UP TENSOR ENVIRONMENT\n",
    "        set_tensor_environment(float_size, random_seed)\n",
    "        if float_size == 16:\n",
    "            self.epsilon = 1e-6\n",
    "            self.dtype = torch.float16\n",
    "        elif float_size == 32:\n",
    "            self.epsilon = 1e-8\n",
    "            self.dtype = torch.float32\n",
    "        elif float_size == 64:\n",
    "            self.epsilon = 1e-8\n",
    "            self.dtype = torch.float64\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        # key parameters:\n",
    "        self.type = \"MLE\"\n",
    "        self.working_dir = working_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.seq_len = data.seq_len\n",
    "        self.alphabet_size = data.alphabet_size\n",
    "        self.convolve_patterns = convolve_patterns\n",
    "        self.convolve_encoder = convolve_encoder\n",
    "        self.final_pwm_scale = final_pwm_scale\n",
    "        self.warm_up = torch.tensor(warm_up,device=self.device,dtype=self.dtype)\n",
    "        self.srng = lambda *shape: torch.randn(*shape, device = self.device, dtype = self.dtype)\n",
    "        self.n_latent = n_latent * n_patterns\n",
    "        self.kl_scale = torch.tensor(kl_scale,device=self.device,dtype=self.dtype)\n",
    "        self.global_scale = torch.tensor(global_scale, device=self.device, dtype=self.dtype)\n",
    "        self.inv_global_scale = torch.tensor((1.0 / global_scale), device=self.device, dtype=self.dtype)\n",
    "        self.sparsity_lambda = sparsity_lambda\n",
    "        self.sparsity = sparsity\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.logit_p = logit_p\n",
    "        self.logit_mu = torch.tensor(np.sqrt(2.0) * logit_sigma * erfinv(2.0 * logit_p - 1.0), device=self.device,\n",
    "                                     dtype=self.dtype)\n",
    "        self.logit_sigma = torch.tensor(logit_sigma, device=self.device, dtype=self.dtype)\n",
    "\n",
    "        # define nn modules with given arguments:\n",
    "        self.encoder = Encoder(encoder_architecture, self.n_latent, convolve_encoder, conv_encoder_size,\n",
    "                               self.alphabet_size, self.seq_len, encode_nonlinearity_type)\n",
    "        self.decoder = DecoderMLE(decoder_architecture, self.n_latent, convolve_patterns, conv_decoder_size,\n",
    "                                  self.alphabet_size, self.seq_len, decode_nonlinearity_type,\n",
    "                                  final_decode_nonlinearity,sparsity,final_pwm_scale,dropout,n_patterns, output_bias)\n",
    "\n",
    "    def sampler(self, mu, logsig):\n",
    "        \"\"\"\n",
    "        Samples from a diagonal Gaussian for stochastic variables. Applies reparameterization trick\n",
    "        :param mu: sample mean\n",
    "        :param logsig: sample log sigma\n",
    "        :return: sampled variable z\n",
    "        \"\"\"\n",
    "        eps = self.srng(mu.shape)\n",
    "        z = mu + torch.exp(logsig) * eps\n",
    "        return z\n",
    "\n",
    "    def _anneal(self, update_num):\n",
    "        \"\"\"\n",
    "        Anneal the KL if using annealing; reduces the KLD loss effect in early updates\n",
    "        :param update_num: current update number\n",
    "        :return: scaling factor for KLD loss\n",
    "        \"\"\"\n",
    "        # If true, return first, else return second\n",
    "        condition = update_num < self.warm_up\n",
    "        KL_scale = torch.where(condition, update_num/self.warm_up,\n",
    "                               torch.tensor(1.0, device=self.device,dtype=self.dtype))\n",
    "        return KL_scale\n",
    "\n",
    "    def update(self, logpxz, mu, logsig, update_num, Neff):\n",
    "        \"\"\"\n",
    "        Calculate updated loss values with regularization and sparsity, returning various loss components.\n",
    "        :param logpxz: Log(P(x|z)) value determined through forward pass of decoder.\n",
    "        :param mu: mu of z determined through forward pass of encoder.\n",
    "        :param logsig: log sigma of z determined through forward pass of encoder\n",
    "        :param update_num: current update number used for annealing if required.\n",
    "        :param Neff: effective sample N, used in loss calculations.\n",
    "        :return: logpx_update - final ELBO loss value,\n",
    "        torch.mean(logpxz) - value for reconstruction loss,\n",
    "        regularization_loss,\n",
    "        torch.mean(KLD_latent) - KL divergence loss of latent variables.\n",
    "        \"\"\"\n",
    "        # calculate KLD of latent variables\n",
    "        KLD_latent = 0.5 * torch.sum(1.0 + 2.0 * logsig - mu**2.0 \\\n",
    "            - torch.exp(2.0 * logsig), dim=1)\n",
    "\n",
    "        # if sparsity used, calculate the sparsity loss depending on which sparsity prior specified.\n",
    "        # include l2 regularization loss in the calculation.\n",
    "        if self.sparsity:\n",
    "            l2_loss = 0.0\n",
    "            if self.l2_lambda > 0.0:\n",
    "                l2_loss += 0.5*torch.sum(self.decoder.hidden1.weight*self.decoder.hidden1.weight)\n",
    "                l2_loss += 0.5*torch.sum(self.decoder.hidden2.weight*self.decoder.hidden2.weight)\n",
    "                if self.convolve_patterns:\n",
    "                    l2_loss += 0.5*torch.sum(self.decoder.conv_layer.weight*self.decoder.conv_layer.weight)\n",
    "                l2_loss += 0.5*torch.sum(self.decoder.final.weight*self.decoder.final.weight)\n",
    "                l2_loss += 0.5*torch.sum(self.decoder.final_pwm_scale*self.decoder.final_pwm_scale)\n",
    "\n",
    "            if self.sparsity == \"logit\":\n",
    "                # Use a continuous relaxation of a spike and slab prior\n",
    "                #    with a logit normit scale distribution\n",
    "                group_sparsity_loss = - torch.sum((-0.5*torch.log(2.0*np.pi*self.logit_sigma**2.0))\\\n",
    "                                                  - ((self.decoder.scale_weight-self.logit_mu)**2.0\\\n",
    "                                                  / (2.0*(self.logit_sigma**2.))))\n",
    "            elif self.sparsity == \"analytic\":\n",
    "                # Use a moment-matched Gaussian approximation to the\n",
    "                #   log-space Hyperbolic Secant hyperprior of the Horseshoe\n",
    "                analytic_mu = torch.log(self.global_scale)\n",
    "                analytic_sigma = np.pi / 2.0\n",
    "                group_sparsity_loss = - torch.sum((-0.5*torch.log(2.*np.pi\\\n",
    "                    *(analytic_sigma**2.0)))\n",
    "                    - ((self.decoder.scale_weight - analytic_mu)**2.0\\\n",
    "                        /(2.*(analytic_sigma**2.0))))\n",
    "            else:\n",
    "                # Estimate KL divergence for the sparsity\n",
    "                # scale parameters (Fadeout) by sampling\n",
    "\n",
    "                out_scale_exp = torch.exp(self.decoder.scale_weight)\n",
    "                if self.sparsity == \"horseshoe\":\n",
    "                    # Horsehoe sparsity has Half-Cauchy hyperprior\n",
    "                    group_sparsity_loss = -torch.sum(torch.log(2.0) + torch.log(self.global_scale) \\\n",
    "                        - torch.log(np.pi) + torch.log(out_scale_exp) \\\n",
    "                        - torch.log(self.global_scale*self.global_scale \\\n",
    "                        + out_scale_exp * out_scale_exp))\n",
    "                elif self.sparsity == \"laplacian\":\n",
    "                    # Laplace sparsity has exponential hyperprior\n",
    "                    group_sparsity_loss = -torch.sum(torch.log(2.0)\\\n",
    "                        + torch.log(self.inverse_global_scale)\\\n",
    "                        - self.inverse_global_scale * out_scale_exp\\\n",
    "                        * out_scale_exp + 2.0 * self.decoder.scale_weight)\n",
    "\n",
    "                elif self.sparsity == \"ard\":\n",
    "                    # Automatic Relevance Determination sparsity\n",
    "                    #  has Inverse-Gamma hyperprior\n",
    "                    group_sparsity_loss = -torch.sum(torch.log(2.0) + (self.global_scale \\\n",
    "                        * torch.log(self.global_scale)) \\\n",
    "                        - gammaln(self.global_scale) - (self.global_scale \\\n",
    "                        / ((out_scale_exp * out_scale_exp) + self.epsilon)) \\\n",
    "                        - (2.0 * self.global_scale * torch.log(out_scale_exp)))\n",
    "        else:\n",
    "            # without sparsity, just calculate the l2 regularisation loss\n",
    "            l2_loss = 0.0\n",
    "            if self.l2_lambda > 0.0:\n",
    "                l2_loss += torch.sum(self.decoder.hidden1.weight*self.decoder.hidden1.weight)\n",
    "                l2_loss += torch.sum(self.decoder.hidden2.weight*self.decoder.hidden2.weight)\n",
    "                if self.convolve_patterns:\n",
    "                    l2_loss += torch.sum(self.decoder.conv_layer.weight*self.decoder.conv_layer.weight)\n",
    "                l2_loss += torch.sum(self.decoder.final.weight*self.decoder.final.weight)\n",
    "                if self.decoder.final_pwm_scale:\n",
    "                    l2_loss += torch.sum(self.decoder.final_pwm_scale*self.decoder.final_pwm_scale)\n",
    "\n",
    "            group_sparsity_loss = 0.0\n",
    "            if self.sparsity_lambda > 0.0:\n",
    "                out_lasso = self.decoder.final.weight.view(self.seq_len, self.decoder.channel_size,\n",
    "                                                           self.decoder.final_output_size).permute(2,0,1)\n",
    "                group_sparsity_loss = torch.sum(torch.sqrt(torch.sum(out_lasso*out_lasso, dim=2)+self.epsilon))\n",
    "\n",
    "        regularization_loss = (-(self.sparsity_lambda * group_sparsity_loss)\\\n",
    "            - (self.l2_lambda * l2_loss)) / Neff\n",
    "\n",
    "        warm_up_scale = self._anneal(update_num)\n",
    "        KLD_latent_update = KLD_latent * self.kl_scale\n",
    "        # get final loss; negative because we want to maximize ELBO and Adam() minimizes\n",
    "        logpx_update = -(torch.mean(logpxz + warm_up_scale * KLD_latent_update) \\\n",
    "                       + (warm_up_scale * regularization_loss))\n",
    "        return logpx_update, torch.mean(logpxz), regularization_loss, torch.mean(KLD_latent)\n",
    "\n",
    "    def likelihoods(self, x):\n",
    "        \"\"\"\n",
    "        calculates ELBO of Log(P(x)) for specific x.\n",
    "        :param x: sequence\n",
    "        :return: logpx_i likelihood value for that x.\n",
    "        \"\"\"\n",
    "        mu, logsig = self.encoder.forward(x)\n",
    "        z = self.sampler(mu, logsig)\n",
    "        reconstructed_x, logpxz, pattern_activations = self.decoder.forward(x, z)\n",
    "        KLD_latent = 0.5 * torch.sum(1.0 + 2.0 * logsig - mu**2.0 - torch.exp(2.0 * logsig), dim=1)\n",
    "        logpx_i = logpxz + KLD_latent\n",
    "        return logpx_i\n",
    "\n",
    "    def all_likelihood_components(self, x):\n",
    "        \"\"\"\n",
    "        As above, but returning all likelihood components individually\n",
    "        :param x: x\n",
    "        :return: likelihood components, KLD of latent space, reconstruction loss, and their sum.\n",
    "        \"\"\"\n",
    "        mu, logsig = self.encoder.forward(x)\n",
    "        z = self.sampler(mu, logsig)\n",
    "        reconstructed_x, logpxz, pattern_activations = self.decoder.forward(x, z)\n",
    "        KLD_latent = 0.5 * torch.sum(1.0 + 2.0 * logsig - mu**2.0 - torch.exp(2.0 * logsig), dim=1)\n",
    "        logpx_i = logpxz + KLD_latent\n",
    "        return logpx_i, KLD_latent, logpxz\n",
    "\n",
    "    def recognize(self, x):\n",
    "        \"\"\"\n",
    "        given a sequence x, return its latent mu and log-sigma.\n",
    "        \"\"\"\n",
    "        mu, logsig = self.encoder.forward(x)\n",
    "        return mu, logsig\n",
    "\n",
    "    def get_pattern_activations(self, x):\n",
    "        \"\"\"\n",
    "        return output patterns for a specific input sequence.\n",
    "        \"\"\"\n",
    "        mu, logsig = self.encoder.forward(x)\n",
    "        z = self.sampler(mu, logsig)\n",
    "        _, _, pattern_activations = self.decoder.forward(x, z)\n",
    "        return pattern_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define our stochastic variational VAE class, VAE_SVI. The main difference here is that this class has methods for determining the KLD loss of variational and sparsity parameters. These are then called by the update function when it determines the full loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_SVI(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder class that implements stochastic variational inference of decoder parameters.\n",
    "    Constructs full model and forward pass, serves as a callable object for model training.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        data,\n",
    "        encoder_architecture=[1500,1500],\n",
    "        decoder_architecture=[100,500],\n",
    "        n_latent=2,\n",
    "        n_patterns=4,\n",
    "        batch_size=100,\n",
    "        encode_nonlinearity_type=\"relu\",\n",
    "        decode_nonlinearity_type=\"relu\",\n",
    "        final_decode_nonlinearity=\"sigmoid\",\n",
    "        sparsity=\"logit\",\n",
    "        global_scale=1.0,\n",
    "        logit_p=0.01,\n",
    "        logit_sigma=4.0,\n",
    "        pattern_sigma=1.0,\n",
    "        warm_up=0.0,\n",
    "        convolve_encoder=False,\n",
    "        convolve_patterns=True,\n",
    "        conv_decoder_size=10,\n",
    "        conv_encoder_size=10,\n",
    "        output_bias=True,\n",
    "        final_pwm_scale=False,\n",
    "        working_dir=\".\",\n",
    "        learning_rate=0.001,\n",
    "        kl_scale=1.0,\n",
    "        random_seed=42,\n",
    "        float_size = 32):\n",
    "        \"\"\"\n",
    "        :param data: instance of DataHelper class with loaded data\n",
    "        :param encoder_architecture: list detailing size of encoder hidden layers\n",
    "        :param decoder_architecture: list detailing size of decoder hidden layers\n",
    "        :param n_latent: size of latent dimension\n",
    "        :param n_patterns: how many times to tile sparsity parameters over output\n",
    "        :param batch_size: size of mini-batch to use\n",
    "        :param encode_nonlinearity_type: non-linearity used in encoder layers\n",
    "        :param decode_nonlinearity_type: non-linearity used in decoder's first layers\n",
    "        :param final_decode_nonlinearity: non-linearity used in decoder's final layer\n",
    "        :param sparsity: Sparsity type, using a noncentered reparameterization.\n",
    "                Options include: logit, analytic, laplacian, horseshoe, ard\n",
    "                See Ingraham and Marks, 2016 (https://arxiv.org/abs/1602.03807)\n",
    "        :param global_scale: Global scale prior for sparsity: analytic, laplacian, horseshoe, ard\n",
    "        :param logit_p: Global scale prior for logit sparsity\n",
    "        :param logit_sigma: Prior sigma for scale prior for logit sparsity\n",
    "        :param pattern_sigma: Prior sigma for variational weights on the final layer\n",
    "        :param warm_up: number of updates for which annealing should be performed, lessening the effect\n",
    "                of KLD loss in early updates.\n",
    "        :param convolve_encoder:  whether to include 1D convolution on the input sequences\n",
    "        :param convolve_patterns: whether to include 1D convolution on output, also known as dictionary\n",
    "        :param conv_decoder_size: size of decoder convolution\n",
    "        :param conv_encoder_size: size of encoder convolution\n",
    "        :param output_bias: whether to include bias on output layer\n",
    "        :param final_pwm_scale: use a temperature parameter on final layer\n",
    "        :param working_dir: directory for saving and loading parameters\n",
    "        :param learning_rate: Adam learning rate\n",
    "        :param kl_scale: Scale of KL of latent variables, default 1.0\n",
    "                Scale < 1.0 approaches a normal autoencoder\n",
    "                Scale > 1.0 turns into beta-autoencoder (Higgins et al, 2016)\n",
    "        :param random_seed: seed for random number generator\n",
    "        :param float_size: 16, 32, 64 - specifies the torch tensor float size.\n",
    "        \"\"\"\n",
    "        super(VAE_SVI, self).__init__()\n",
    "        # SET UP TENSOR ENVIRONMENT\n",
    "        set_tensor_environment(float_size, random_seed)\n",
    "        if float_size == 16:\n",
    "            self.epsilon = 1e-6\n",
    "            self.dtype = torch.float16\n",
    "        elif float_size == 32:\n",
    "            self.epsilon = 1e-8\n",
    "            self.dtype = torch.float32\n",
    "        elif float_size == 64:\n",
    "            self.epsilon = 1e-8\n",
    "            self.dtype = torch.float64\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda:0')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        # key parameters:\n",
    "        self.type = 'SVI'\n",
    "        self.convolve_patterns = convolve_patterns\n",
    "        self.convolve_encoder = convolve_encoder\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.seq_len = data.seq_len\n",
    "        self.alphabet_size = data.alphabet_size\n",
    "        self.warm_up = torch.tensor(warm_up, device=self.device, dtype=self.dtype)\n",
    "        self.sigma_init = 0.01\n",
    "        self.logsig_init = -5\n",
    "        self.srng = lambda *shape: torch.randn(*shape, device=self.device, dtype=self.dtype)\n",
    "        self.working_dir = working_dir\n",
    "        self.sparsity = sparsity\n",
    "        self.final_pwm_scale = final_pwm_scale\n",
    "        self.logit_mu = torch.tensor(np.sqrt(2.0)*logit_sigma*erfinv(2.0*logit_p-1.0),\n",
    "                                     device=self.device, dtype=self.dtype)\n",
    "        self.logit_sigma = torch.tensor(logit_sigma, device=self.device, dtype=self.dtype)\n",
    "        self.global_scale = torch.tensor(global_scale, device=self.device, dtype=self.dtype)\n",
    "        self.kl_scale = torch.tensor(kl_scale, device=self.device, dtype=self.dtype)\n",
    "        self.global_scale = torch.tensor(global_scale, device=self.device, dtype=self.dtype)\n",
    "        self.inv_global_scale = torch.tensor((1.0/global_scale), device=self.device, dtype=self.dtype)\n",
    "        self.logit_p = logit_p\n",
    "        self.sigma_init = 0.01\n",
    "        self.logsig_init = -5\n",
    "\n",
    "        # define nn modules with given arguments:\n",
    "        self.encoder = Encoder(encoder_architecture, n_latent, convolve_encoder, conv_encoder_size,\n",
    "                 self.alphabet_size, self.seq_len, encode_nonlinearity_type)\n",
    "\n",
    "        self.decoder = DecoderSVI(decoder_architecture, n_latent, convolve_patterns, conv_decoder_size,\n",
    "                                  self.alphabet_size, self.seq_len, decode_nonlinearity_type,\n",
    "                                  final_decode_nonlinearity, sparsity, final_pwm_scale, n_patterns,\n",
    "                                  output_bias, self.logsig_init, pattern_sigma, self.srng)\n",
    "\n",
    "    def KLD_diag_gaussians(self, mu, logsig, p_mu, p_logsig):\n",
    "        \"\"\"\n",
    "        KLD divergence between diagonal gaussian with prior diagonal gaussian\n",
    "        :param mu: mean value of gaussian\n",
    "        :param logsig: log sigma of gaussian\n",
    "        :param p_mu: mu of prior gaussian\n",
    "        :param p_logsig: log sigma of prior gaussian\n",
    "        :return: KL divergence value\n",
    "        \"\"\"\n",
    "        KLD = p_logsig - logsig + 0.5*(torch.exp(2.0*logsig)+torch.pow(mu-p_mu,2))*torch.exp(-2.0*p_logsig)-0.5\n",
    "        return KLD\n",
    "\n",
    "    def sampler(self, mu, logsig):\n",
    "        \"\"\"\n",
    "        Samples from a diagonal Gaussian for stochastic variables. Applies reparameterization trick\n",
    "        :param mu: sample mean\n",
    "        :param logsig: sample log sigma\n",
    "        :return: sampled variable z\n",
    "        \"\"\"\n",
    "        eps = self.srng(mu.shape)\n",
    "        z = mu + torch.exp(logsig) * eps\n",
    "        return z\n",
    "\n",
    "    def _anneal(self, update_num):\n",
    "        \"\"\"\n",
    "        Anneal the KL if using annealing; reduces the KLD loss effect in early updates\n",
    "        :param update_num: current update number\n",
    "        :return: scaling factor for KLD loss\n",
    "        \"\"\"\n",
    "        # If true, return first, else return second\n",
    "        condition = update_num < self.warm_up\n",
    "        KL_scale = torch.where(condition, update_num/self.warm_up,\n",
    "                               torch.tensor(1.0, device=self.device, dtype=self.dtype))\n",
    "        return KL_scale\n",
    "\n",
    "    def gen_kld_params(self):\n",
    "        \"\"\"\n",
    "        Iterates through all variational parameters using their identifiers and the model's state_dict(),\n",
    "        calculated KL divergence value, summing over all parameters\n",
    "        :return: sum of KLD losses\n",
    "        \"\"\"\n",
    "        KLD_params = 0.0\n",
    "        for identifier in self.decoder.variational_param_identifiers: # iterate over every variational parameter\n",
    "            mu_id = \"mu_\"+identifier # construct IDs for mu and logsigma parameters\n",
    "            ls_id = \"ls_\"+identifier\n",
    "            pl_id = identifier[0:2] # get ID for prior logsig list\n",
    "            mu = self.decoder.state_dict(keep_vars=True)[mu_id].flatten() #extract weights with gradients\n",
    "            ls = self.decoder.state_dict(keep_vars=True)[ls_id].flatten()\n",
    "            prior_sg = torch.tensor(self.decoder.variational_param_name_to_sigma[pl_id], # extract prior sigma\n",
    "                                    device=self.device, dtype=self.dtype)\n",
    "            prior_ls = torch.log(prior_sg) # convert to log-sigma\n",
    "            KLD_params += 4*torch.sum(-self.KLD_diag_gaussians(mu,ls,0.0,prior_ls)) # calculate KLD loss, summing\n",
    "        return KLD_params # return sum of losses\n",
    "\n",
    "    def gen_kld_sparsity(self, sparsity):\n",
    "        \"\"\"\n",
    "        Calculates KL divergence loss for sparsity parameters depending on what sparsity is used\n",
    "        :param sparsity: specified sparsity to use\n",
    "        :return: KL divergence loss\n",
    "        \"\"\"\n",
    "        if sparsity == \"logit\":\n",
    "            # Use a continuous relaxation of a spike and slab prior\n",
    "            # with a logit normit scale distribution\n",
    "            KLD_fadeout = -self.KLD_diag_gaussians(\n",
    "                self.decoder.state_dict(keep_vars=True)['scale_mu'],\n",
    "                self.decoder.state_dict(keep_vars=True)['scale_ls'],\n",
    "                self.logit_mu,\n",
    "                torch.log(self.logit_sigma)\n",
    "            )\n",
    "        if sparsity == \"analytic\":\n",
    "            # Use a moment-matched Gaussian approximation to the\n",
    "            #   log-space Hyperbolic Secant hyperprior of the Horseshoe\n",
    "            KLD_fadeout = -self.KLD_diag_gaussians(\n",
    "                self.decoder.state_dict(keep_vars=True)['scale_mu'],\n",
    "                self.decoder.state_dict(keep_vars=True)['scale_ls'],\n",
    "                torch.log(self.global_scale),\n",
    "                torch.log(np.pi/2.0)\n",
    "            )\n",
    "        else:\n",
    "            # Estimate KL divergence for the sparsity\n",
    "            #   scale parameters (Fadeout) by sampling\n",
    "            W_scale = torch.exp(self.sampler(\n",
    "                self.decoder.state_dict(keep_vars=True)['scale_mu'],\n",
    "                self.decoder.state_dict(keep_vars=True)['scale_ls']\n",
    "            ))\n",
    "            if sparsity == \"horseshoe\":\n",
    "                KLD_fadeout = (torch.log(2.0) + torch.log(self.global_scale) - torch.log(np.pi) + torch.log(W_scale) \\\n",
    "                    - torch.log(self.global_scale*self.global_scale + W_scale*W_scale)) \\\n",
    "                    + (self.decoder.state_dict(keep_vars=True)['scale_ls'] + 0.5*torch.log(2.0*np.pi*np.e))\n",
    "            elif sparsity == 'laplacian':\n",
    "                # Laplace sparsity has exponential hyperprior\n",
    "                KLD_fadeout = (torch.log(2.0) + torch.log(self.inv_global_scale) \\\n",
    "                    - self.inv_global_scale * W_scale * W_scale + 2.0 \\\n",
    "                    * torch.log(W_scale)) + (self.decoder.state_dict(keep_vars=True)['scale_ls'] \\\n",
    "                    + 0.5 * torch.log(2.0 * np.pi * np.e))\n",
    "            elif sparsity == \"ard\":\n",
    "                # Automatic Relevance Determination sparsity\n",
    "                #  has Inverse-Gamma hyperprior\n",
    "                KLD_fadeout = (torch.log(2.0) + (self.global_scale \\\n",
    "                    * torch.log(self.global_scale)) \\\n",
    "                    - gammaln(self.global_scale) - (self.global_scale \\\n",
    "                    / ((W_scale * W_scale) + self.epsilon)) \\\n",
    "                    - (2.0 * self.global_scale * torch.log(W_scale))) \\\n",
    "                    + (self.decoder.state_dict(keep_vars=True)['scale_ls']  \\\n",
    "                    + 0.5 * torch.log(2.0 * np.pi * np.e))\n",
    "        return torch.sum(KLD_fadeout)\n",
    "\n",
    "    def update(self, logpxz, mu, logsig, update_num, Neff):\n",
    "        \"\"\"\n",
    "        Calculate updated loss values with KLD loss and sparsity, returning various loss components.\n",
    "        :param logpxz: Log(P(x|z)) value determined through forward pass of decoder.\n",
    "        :param mu: mu of z determined through forward pass of encoder.\n",
    "        :param logsig: log sigma of z determined through forward pass of encoder\n",
    "        :param update_num: current update number used for annealing if required.\n",
    "        :param Neff: effective sample N, used in loss calculations.\n",
    "        :return: logpx_update - final ELBO loss value,\n",
    "        torch.mean(logpxz) - value for reconstruction loss,\n",
    "        regularization_loss,\n",
    "        torch.mean(KLD_latent) - KL divergence loss of latent variables.\n",
    "        \"\"\"\n",
    "        # latent dimension KL divergence loss\n",
    "        KLD_latent = 0.5*torch.sum(1.0 + 2.0*logsig - torch.pow(mu,2) - torch.exp(2.0*logsig), dim=1)\n",
    "        # decoder parameter KL divergence loss\n",
    "        KLD_params_all = self.gen_kld_params()\n",
    "        # sparsity parameter KL divergence loss\n",
    "        if self.sparsity:\n",
    "            KLD_params_all += self.gen_kld_sparsity(self.sparsity)\n",
    "        # get warm up scale for latent space if using annealing\n",
    "        warm_up_scale = self._anneal(update_num)\n",
    "        # apply KL scale if using\n",
    "        KLD_latent_update = KLD_latent * self.kl_scale\n",
    "        # get final loss; negative because we want to maximize ELBO and Adam() minimizes\n",
    "        logpx_update = -(torch.mean(logpxz + (warm_up_scale * KLD_latent_update)) \\\n",
    "            + (warm_up_scale * (KLD_params_all / Neff)))\n",
    "        # return all loss components\n",
    "        return logpx_update, torch.mean(logpxz), (KLD_params_all/Neff), torch.mean(KLD_latent)\n",
    "\n",
    "    def likelihoods(self, x):\n",
    "        \"\"\"\n",
    "        calculates ELBO of Log(P(x)) for specific x.\n",
    "        :param x: sequence\n",
    "        :return: logpx_i likelihood value for that x.\n",
    "        \"\"\"\n",
    "        mu, logsig = self.encoder.forward(x)\n",
    "        z = self.sampler(mu, logsig)\n",
    "        reconstructed_x, logpxz, pattern_activations = self.decoder.forward(x, z)\n",
    "        KLD_latent = 0.5*torch.sum(1.0 + 2.0*logsig - mu**2.0 - torch.exp(2.0*logsig), dim=1)\n",
    "        logpx_i = logpxz + KLD_latent\n",
    "        return logpx_i\n",
    "\n",
    "    def all_likelihood_components(self, x):\n",
    "        \"\"\"\n",
    "        As above, but returning all likelihood components individually. Used in effect prediction\n",
    "        :param x: x\n",
    "        :return: likelihood components, KLD of latent space, reconstruction loss, and their sum.\n",
    "        \"\"\"\n",
    "        mu, logsig = self.encoder.forward(x)\n",
    "        z = self.sampler(mu, logsig)\n",
    "        reconstructed_x, logpxz, pattern_activations = self.decoder.forward(x, z)\n",
    "        KLD_latent = 0.5 * torch.sum(1.0 + 2.0 * logsig - mu**2.0 - torch.exp(2.0 * logsig), dim=1)\n",
    "        logpx_i = logpxz + KLD_latent\n",
    "        return logpx_i, KLD_latent, logpxz\n",
    "\n",
    "    def recognize(self, x):\n",
    "        \"\"\"\n",
    "        given a sequence x, return its latent mu and log-sigma.\n",
    "        \"\"\"\n",
    "        mu, logsig = self.encoder.forward(x)\n",
    "        return mu, logsig\n",
    "\n",
    "    def get_pattern_activations(self, x):\n",
    "        \"\"\"\n",
    "        return output patterns for a specific input sequence.\n",
    "        \"\"\"\n",
    "        mu, logsig = self.encoder.forward(x)\n",
    "        z = self.sampler(mu, logsig)\n",
    "        _, _, pattern_activations = self.decoder.forward(x, z)\n",
    "        return pattern_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pt_train.py\n",
    "\n",
    "This module, which can be found [here](https://github.com/rorymaizels/AC299r/blob/master/models/model_code/pt_train.py) is responsible for saving, loading and training models.\n",
    "\n",
    "The save and load functions are essentially wrappers for PyTorch's own saving and loading functions, with some added functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, file_prefix='unnamed_model', working_dir=\".\",):\n",
    "    \"\"\" save the given model with given name in given directory\"\"\"\n",
    "    file_path = working_dir + '/model_params/' + file_prefix\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "\n",
    "\n",
    "def load(model, path, eval=True, cuda=True):\n",
    "    \"\"\"\n",
    "    load model weights\n",
    "    :param model: model with weights to be updated\n",
    "    :param path: path to weights\n",
    "    :param eval: set model to eval() mode\n",
    "    :param cuda: enable GPU/cuda\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    if cuda:\n",
    "        model.load_state_dict(torch.load(path))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(path, map_location='cpu'))\n",
    "    if eval:\n",
    "        model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train function performs the core model training, accepting a pre-constructed model and datahelper in its arguments. Through arguments, one can alter verbosity, printing rate, saving functions etc - as well as, of course, the number of updates to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data,\n",
    "    model,\n",
    "    save_progress=False,\n",
    "    save_parameters=False,\n",
    "    num_updates=300000,\n",
    "    verbose=True,\n",
    "    job_string=\"\",\n",
    "    embeddings=False,\n",
    "    update_offset=0,\n",
    "    print_neff=True,\n",
    "    print_iter=1,\n",
    "    use_cuda=False):\n",
    "    \"\"\"\n",
    "    Main function to train DeepSequence models\n",
    "    :param data: DataHelper class instance\n",
    "    :param model: Model class instance\n",
    "    :param save_progress: save log files of losses during training\n",
    "    :param save_parameters: number of iterations on which to save parameters\n",
    "    :param num_updates: number of training iterations / epochs\n",
    "    :param verbose: Print losses and details\n",
    "    :param job_string: string for saving model etc.\n",
    "    :param embeddings:  save latent variables every k iterations (int)\n",
    "            or \"log\": save latent variables during training on log scale iterations\n",
    "            or False (bool)\n",
    "    :param update_offset:  Offset use for Adam in training\n",
    "            Change this to keep training parameters from an old model\n",
    "    :param print_neff: Print the effective sample size of the alignment\n",
    "    :param print_iter: how many iterations to print information if verbose\n",
    "    :param use_cuda: GPU/cuda capability\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    torch_dtype = model.dtype\n",
    "    torch_device = model.device\n",
    "    batch_size = model.batch_size\n",
    "    batch_order = np.arange(data.x_train.shape[0])\n",
    "    seq_sample_probs = data.weights / np.sum(data.weights)\n",
    "    update_num = 0\n",
    "    LB_list = []\n",
    "    reg_list = []\n",
    "    KLD_latent_list = []\n",
    "    recon_list = []\n",
    "\n",
    "    if save_progress:\n",
    "        err_filename = data.working_dir+\"/logs/\"+job_string+\"_err.csv\"\n",
    "        OUTPUT = open(err_filename, \"w+\")\n",
    "        if print_neff:\n",
    "            OUTPUT.write(\"Neff:\\t\"+str(data.Neff)+\"\\n\")\n",
    "        OUTPUT.close()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    if embeddings == \"log\":\n",
    "        start_embeddings = 10\n",
    "        log_embedding_interpolants = sorted(list(set(np.floor(np.exp(\\\n",
    "            np.linspace(np.log(start_embeddings),np.log(50000),1250))).tolist())))\n",
    "        log_embedding_interpolants = [int(val) for val in log_embedding_interpolants]\n",
    "\n",
    "    solver = optim.Adam(model.parameters(), lr=model.learning_rate)\n",
    "\n",
    "    while (update_num + update_offset) < num_updates:\n",
    "        # iterate\n",
    "        update_num += 1\n",
    "        # prepare data\n",
    "        batch_index = np.random.choice(batch_order, batch_size, \\\n",
    "            p=seq_sample_probs).tolist()\n",
    "        batch = torch.tensor(data.x_train[batch_index], dtype=torch_dtype, device=torch_device, requires_grad=False)\n",
    "\n",
    "        if use_cuda:\n",
    "            batch = batch.cuda()\n",
    "            model = model.cuda()\n",
    "        neff = data.Neff\n",
    "\n",
    "        solver.zero_grad() # torch accumulates gradients, so this should be called to reset\n",
    "\n",
    "        # forward step\n",
    "        batch_mu, batch_logsig = model.encoder.forward(batch)\n",
    "        batch_z = model.sampler(batch_mu,batch_logsig)\n",
    "        batch_recon, logpxz, output = model.decoder.forward(batch, batch_z)\n",
    "\n",
    "        # find loss\n",
    "        LB_loss, recon_entropy, reg_loss, KLD_latent = model.update(logpxz, batch_mu, batch_logsig, update_num, neff)\n",
    "\n",
    "        # store results of different loss components.\n",
    "        LB_list.append(LB_loss.cpu().detach().numpy())\n",
    "        reg_list.append(reg_loss.cpu().detach().numpy())\n",
    "        KLD_latent_list.append(KLD_latent.cpu().detach().numpy())\n",
    "        recon_list.append(recon_entropy.cpu().detach().numpy())\n",
    "\n",
    "        # backward step\n",
    "        LB_loss.backward()\n",
    "\n",
    "        # update\n",
    "        solver.step()\n",
    "\n",
    "        #housekeeping; stop gradients accumulating\n",
    "        for p in model.parameters():\n",
    "            p.grad.data.zero_()\n",
    "\n",
    "        # saving functions\n",
    "        if save_parameters != False and update_num % save_parameters == 0:\n",
    "            if verbose:\n",
    "                print(\"Saving Parameters\")\n",
    "            name = job_string+\"_epoch\"+str(update_num+update_offset)\n",
    "            save(model, name)\n",
    "\n",
    "        # Make embeddings in roughly log-time\n",
    "        if embeddings:\n",
    "            if embeddings == \"log\":\n",
    "                if update_num + update_offset in log_embedding_interpolants:\n",
    "                    data.get_embeddings(model, update_num + update_offset, filename_prefix=job_string)\n",
    "            else:\n",
    "                if update_num % embeddings == 0:\n",
    "                    data.get_embeddings(model, update_num + update_offset, filename_prefix=job_string)\n",
    "\n",
    "        if update_num % print_iter == 0: # printing if verbose, saving loss to log files if saving progress\n",
    "            mean_index = np.arange(update_num-print_iter,update_num)\n",
    "\n",
    "            LB = np.mean(np.asarray(LB_list)[mean_index])\n",
    "            KLDP = np.mean(np.asarray(reg_list)[mean_index])\n",
    "            KLDL = np.mean(np.asarray(KLD_latent_list)[mean_index])\n",
    "            reconstruct = np.mean(np.asarray(recon_list)[mean_index])\n",
    "\n",
    "            template = \"Update {0}. LB : {1:.2f}, Params: {2:.2f}, Latent: {3:.2f}, Reconstruct: {4:.2f}, Time: {5:.2f}\"\n",
    "            progress = template.format(update_num+update_offset, LB, KLDP, KLDL, reconstruct, time.time() - start)\n",
    "\n",
    "            if verbose:\n",
    "                print(progress)\n",
    "\n",
    "            if save_progress:\n",
    "                OUTPUT = open(err_filename, \"a\")\n",
    "                OUTPUT.write(progress+\"\\n\")\n",
    "                OUTPUT.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run_ptsvi.py\n",
    "\n",
    "This is the simple script used to actually run the SVI_VAE model training - it can be found [here](https://github.com/rorymaizels/AC299r/blob/master/models/running_code/run_ptsvi.py). Because the SVI and MLE models have different structure and different features, training and testing these models use different scripts for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "# to store and access model code in different folders, use this example command:\n",
    "# sys.path.insert(0, \"../model_code/\")\n",
    "import pt_model\n",
    "import pt_helper\n",
    "import pt_train\n",
    "\n",
    "# specify the data set to use and any other DataHelper parameters\n",
    "data_params = {\n",
    "    \"dataset\"           :   \"BLAT_ECOLX\"\n",
    "    }\n",
    "\n",
    "#specify model details\n",
    "model_params = {\n",
    "    \"bs\"                :   100,\n",
    "    \"encode_dim_zero\"   :   1500,\n",
    "    \"encode_dim_one\"    :   1500,\n",
    "    \"decode_dim_zero\"   :   100,\n",
    "    \"decode_dim_one\"    :   500,\n",
    "    \"n_latent\"          :   30,\n",
    "    \"logit_p\"           :   0.001,\n",
    "    \"sparsity\"          :   \"logit\",\n",
    "    \"final_decode_nonlin\":  \"sigmoid\",\n",
    "    \"final_pwm_scale\"   :   True,\n",
    "    \"n_pat\"             :   4,\n",
    "    \"r_seed\"            :   12345,\n",
    "    \"conv_pat\"          :   True,\n",
    "    \"convolve_encoder\"  :   False,\n",
    "    'warm_up'           :   0.0,\n",
    "    \"d_c_size\"          :   40\n",
    "    }\n",
    "\n",
    "# specify training details\n",
    "train_params = {\n",
    "    \"num_updates\"       :   3,\n",
    "    \"save_progress\"     :   False,\n",
    "    \"verbose\"           :   True,\n",
    "    \"save_parameters\"   :   False,\n",
    "    \"unique_ID\"         :   \"test_run\",\n",
    "    \"cuda\"              :   False\n",
    "    }\n",
    "\n",
    "# speed up run time with GPU and algorithmic benchmarking\n",
    "cuda = torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# construct data, model and train!\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_helper = pt_helper.DataHelper(dataset=data_params[\"dataset\"],\n",
    "                                        calc_weights=True)\n",
    "    vae_model = pt_model.VAE_SVI(data_helper,\n",
    "                                   batch_size=model_params[\"bs\"],\n",
    "                                   encoder_architecture=[model_params[\"encode_dim_zero\"],\n",
    "                                                         model_params[\"encode_dim_one\"]],\n",
    "                                   decoder_architecture=[model_params[\"decode_dim_zero\"],\n",
    "                                                         model_params[\"decode_dim_one\"]],\n",
    "                                   n_latent=model_params[\"n_latent\"],\n",
    "                                   logit_p=model_params[\"logit_p\"],\n",
    "                                   sparsity=model_params[\"sparsity\"],\n",
    "                                   encode_nonlinearity_type=\"relu\",\n",
    "                                   decode_nonlinearity_type=\"relu\",\n",
    "                                   final_decode_nonlinearity=model_params[\"final_decode_nonlin\"],\n",
    "                                   final_pwm_scale=model_params[\"final_pwm_scale\"],\n",
    "                                   conv_decoder_size=model_params[\"d_c_size\"],\n",
    "                                   convolve_patterns=model_params[\"conv_pat\"],\n",
    "                                   convolve_encoder=model_params[\"convolve_encoder\"],\n",
    "                                   n_patterns=model_params[\"n_pat\"],\n",
    "                                   random_seed=model_params[\"r_seed\"],\n",
    "                                   warm_up=model_params['warm_up']\n",
    "                                   )\n",
    "    job_string = pt_helper.gen_simple_job_string(vae_model, data_params, train_params[\"unique_ID\"])\n",
    "\n",
    "    print(\"MODEL PARAMS:\")\n",
    "    print(model_params)\n",
    "    print(\"TRAINING PARAMS:\")\n",
    "    print(train_params)\n",
    "    print(\"Data:\")\n",
    "    print(data_params)\n",
    "\n",
    "    pt_train.train(data_helper, vae_model,\n",
    "        num_updates             =   train_params[\"num_updates\"],\n",
    "        save_progress           =   train_params[\"save_progress\"],\n",
    "        save_parameters         =   train_params[\"save_parameters\"],\n",
    "        verbose                 =   train_params[\"verbose\"],\n",
    "        job_string              =   job_string,\n",
    "        use_cuda                =   train_params[\"cuda\"])\n",
    "\n",
    "    pt_train.save(vae_model, job_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run_ptmle.py\n",
    "\n",
    "Analogous to above, but found [here](https://github.com/rorymaizels/AC299r/blob/master/models/running_code/run_ptmle.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# to store and access model code in different folders, use this example command:\n",
    "import sys\n",
    "# sys.path.insert(0, \"../model_code/\")\n",
    "import pt_model\n",
    "import pt_helper\n",
    "import pt_train\n",
    "\n",
    "# specify the data set to use and any other DataHelper parameters\n",
    "data_params = {\n",
    "    \"dataset\"           :   \"BLAT_ECOLX\"\n",
    "    }\n",
    "\n",
    "# specify model details\n",
    "model_params = {\n",
    "    \"bs\"                :   100,\n",
    "    \"encode_dim_zero\"   :   1500,\n",
    "    \"encode_dim_one\"    :   1500,\n",
    "    \"decode_dim_zero\"   :   100,\n",
    "    \"decode_dim_one\"    :   500,\n",
    "    \"n_latent\"          :   30,\n",
    "    \"logit_p\"           :   0.001,\n",
    "    \"sparsity\"          :   \"logit\",\n",
    "    \"f_nonlin\"          :  \"sigmoid\",\n",
    "    \"fps\"               :   True,\n",
    "    \"n_pat\"             :   4,\n",
    "    \"r_seed\"            :   1,\n",
    "    \"conv_pat\"          :   True,\n",
    "    \"d_c_size\"          :   40,\n",
    "    \"sparsity_l\"        :   1.0,\n",
    "    \"l2_l\"              :   1.0,\n",
    "    \"dropout\"           :   True,\n",
    "    }\n",
    "\n",
    "# specify training details\n",
    "train_params = {\n",
    "    \"num_updates\"       :   3,\n",
    "    \"save_progress\"     :   False,\n",
    "    \"verbose\"           :   True,\n",
    "    \"save_parameters\"   :   False,\n",
    "    \"unique_ID\"         :   \"test_run\",\n",
    "    \"cuda\"              :   False\n",
    "    }\n",
    "\n",
    "# speed up runtime with GPUs and algorithmic benchmarking\n",
    "cuda = torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# construct data, model and train!\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_helper = pt_helper.DataHelper(data_params[\"dataset\"], calc_weights=True)\n",
    "\n",
    "    vae_model   = pt_model.VAE_MLE(data_helper,\n",
    "        batch_size                     =   model_params[\"bs\"],\n",
    "        encoder_architecture           =   [model_params[\"encode_dim_zero\"],\n",
    "                                                model_params[\"encode_dim_one\"]],\n",
    "        decoder_architecture           =   [model_params[\"decode_dim_zero\"],\n",
    "                                                model_params[\"decode_dim_one\"]],\n",
    "        n_latent                       =   model_params[\"n_latent\"],\n",
    "        logit_p                        =   model_params[\"logit_p\"],\n",
    "        encode_nonlinearity_type       =   \"relu\",\n",
    "        decode_nonlinearity_type       =   \"relu\",\n",
    "        final_decode_nonlinearity      =   model_params[\"f_nonlin\"],\n",
    "        final_pwm_scale                =   model_params[\"fps\"],\n",
    "        conv_decoder_size              =   model_params[\"d_c_size\"],\n",
    "        convolve_patterns              =   model_params[\"conv_pat\"],\n",
    "        n_patterns                     =   model_params[\"n_pat\"],\n",
    "        random_seed                    =   model_params[\"r_seed\"],\n",
    "        sparsity_lambda                =   model_params[\"sparsity_l\"],\n",
    "        l2_lambda                      =   model_params[\"l2_l\"],\n",
    "        sparsity                       =   model_params[\"sparsity\"])\n",
    "\n",
    "    job_string = pt_helper.gen_simple_job_string(vae_model, data_params, train_params[\"unique_ID\"])\n",
    "\n",
    "    print(\"MODEL PARAMS:\")\n",
    "    print(model_params)\n",
    "    print(\"TRAINING PARAMS:\")\n",
    "    print(train_params)\n",
    "    print(\"Data:\")\n",
    "    print(data_params)\n",
    "\n",
    "    pt_train.train(data_helper, vae_model,\n",
    "        num_updates             =   train_params[\"num_updates\"],\n",
    "        save_progress           =   train_params[\"save_progress\"],\n",
    "        save_parameters         =   train_params[\"save_parameters\"],\n",
    "        verbose                 =   train_params[\"verbose\"],\n",
    "        job_string              =   job_string,\n",
    "        use_cuda                =   train_params[\"cuda\"])\n",
    "\n",
    "    pt_train.save(vae_model, job_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI_mutation_analysis.py & MLE_mutation_analysis.py\n",
    "\n",
    "These scripts are used to compare predictions with experimental data. These are largely based on code already written before the project but are included for reference. The code is designed for csv files collected by the lab, and would likely need to be re-written for experimental data of different formats. Regardless, they serve as an example of how to analyse model performance in this context. The SVI version is [here](https://github.com/rorymaizels/AC299r/blob/master/models/running_code/SVI_mutation_analysis.py) and the MLE version is [here](https://github.com/rorymaizels/AC299r/blob/master/models/running_code/MLE_mutation_analysis.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVI_mutation_analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "# use following command if model code in different directory\n",
    "import sys\n",
    "# sys.path.insert(0, \"../model_code/\")\n",
    "import pt_model as model\n",
    "import pt_helper as helper\n",
    "import pt_train as train\n",
    "\n",
    "# specify path to model parameters\n",
    "model_name = \"\"\n",
    "\n",
    "# specify dataset\n",
    "data_params = {\"dataset\":\"BLAT_ECOLX\"}\n",
    "\n",
    "# specify model params\n",
    "model_params = {\n",
    "    \"bs\"                :   100,\n",
    "    \"encode_dim_zero\"   :   1500,\n",
    "    \"encode_dim_one\"    :   1500,\n",
    "    \"decode_dim_zero\"   :   500,\n",
    "    \"decode_dim_one\"    :   1500,\n",
    "    \"n_latent\"          :   30,\n",
    "    \"logit_p\"           :   0.001,\n",
    "    \"sparsity\"          :   \"logit\",\n",
    "    \"final_decode_nonlin\":  \"sigmoid\",\n",
    "    \"final_pwm_scale\"   :   True,\n",
    "    \"n_pat\"             :   4,\n",
    "    \"r_seed\"            :   12345,\n",
    "    \"conv_pat\"          :   True,\n",
    "    \"convolve_encoder\"  :   False,\n",
    "    \"d_c_size\"          :   40\n",
    "    }\n",
    "\n",
    "def generate_spearmanr(mutant_name_list, delta_elbo_list, mutation_filename, phenotype_name):\n",
    "    \"\"\"\n",
    "    function that takes in mutant data from model and experimental data and prints a Spearman R correlation coefficient.\n",
    "    \"\"\"\n",
    "    measurement_df = pd.read_csv(mutation_filename, sep=',')\n",
    "\n",
    "    mutant_list = measurement_df.mutant.tolist()\n",
    "    expr_values_ref_list = measurement_df[phenotype_name].tolist()\n",
    "\n",
    "    mutant_name_to_pred = {mutant_name_list[i]: delta_elbo_list[i] for i in range(len(delta_elbo_list))}\n",
    "\n",
    "    # If there are measurements\n",
    "    wt_list = []\n",
    "    preds_for_spearmanr = []\n",
    "    measurements_for_spearmanr = []\n",
    "\n",
    "    for i, mutant_name in enumerate(mutant_list):\n",
    "        expr_val = expr_values_ref_list[i]\n",
    "\n",
    "        # Make sure we have made a prediction for that mutant\n",
    "        if mutant_name in mutant_name_to_pred:\n",
    "            multi_mut_name_list = mutant_name.split(':')\n",
    "\n",
    "            # If there is no measurement for that mutant, pass over it\n",
    "            if np.isnan(expr_val):\n",
    "                pass\n",
    "\n",
    "            # If it was a codon change, add it to the wt vals to average\n",
    "            elif mutant_name[0] == mutant_name[-1] and len(multi_mut_name_list) == 1:\n",
    "                wt_list.append(expr_values_ref_list[i])\n",
    "\n",
    "            # If it is labeled as the wt sequence, add it to the average list\n",
    "            elif mutant_name == 'wt' or mutant_name == 'WT':\n",
    "                wt_list.append(expr_values_ref_list[i])\n",
    "\n",
    "            else:\n",
    "                measurements_for_spearmanr.append(expr_val)\n",
    "                preds_for_spearmanr.append(mutant_name_to_pred[mutant_name])\n",
    "\n",
    "    if wt_list != []:\n",
    "        measurements_for_spearmanr.append(np.mean(wt_list))\n",
    "        preds_for_spearmanr.append(0.0)\n",
    "\n",
    "    num_data = len(measurements_for_spearmanr)\n",
    "    spearman_r, spearman_pval = ss.spearmanr(measurements_for_spearmanr, preds_for_spearmanr)\n",
    "    print(\"N: \" + str(num_data) + \", Spearmanr: \" + str(spearman_r) + \", p-val: \" + str(spearman_pval))\n",
    "\n",
    "\n",
    "# make datahelper and model\n",
    "data_helper = helper.DataHelper(dataset=data_params[\"dataset\"], working_dir=\".\", calc_weights=False)\n",
    "\n",
    "vae_model = model.VAE_SVI(data_helper,\n",
    "                          batch_size=model_params[\"bs\"],\n",
    "                          encoder_architecture=[model_params[\"encode_dim_zero\"],\n",
    "                                                model_params[\"encode_dim_one\"]],\n",
    "                          decoder_architecture=[model_params[\"decode_dim_zero\"],\n",
    "                                                model_params[\"decode_dim_one\"]],\n",
    "                          n_latent=model_params[\"n_latent\"],\n",
    "                          logit_p=model_params[\"logit_p\"],\n",
    "                          sparsity=model_params[\"sparsity\"],\n",
    "                          encode_nonlinearity_type=\"relu\",\n",
    "                          decode_nonlinearity_type=\"relu\",\n",
    "                          final_decode_nonlinearity=model_params[\"final_decode_nonlin\"],\n",
    "                          final_pwm_scale=model_params[\"final_pwm_scale\"],\n",
    "                          conv_decoder_size=model_params[\"d_c_size\"],\n",
    "                          convolve_patterns=model_params[\"conv_pat\"],\n",
    "                          convolve_encoder=model_params[\"convolve_encoder\"],\n",
    "                          n_patterns=model_params[\"n_pat\"],\n",
    "                          random_seed=model_params[\"r_seed\"],\n",
    "                          )\n",
    "\n",
    "print (\"Model built\")\n",
    "\n",
    "path = \"model_params/\"+model_name\n",
    "# load weights\n",
    "train.load(vae_model, path)\n",
    "print (\"Parameters loaded\\n\\n\")\n",
    "mutation = \"mutations/BLAT_ECOLX_Ranganathan2015.csv\"\n",
    "\n",
    "# construct model's mutation predictions\n",
    "custom_mutant_name_list, custom_delta_elbos = data_helper.custom_mutant_matrix(mutation,\n",
    "                                                                               vae_model,\n",
    "                                                                               N_pred_iterations=500)\n",
    "# find Spearman R value\n",
    "generate_spearmanr(custom_mutant_name_list, custom_delta_elbos, mutation, \"2500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MLE_mutation_analysis\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "# use following command if models are in different directory\n",
    "# sys.path.insert(0, \"../model_code/\")\n",
    "import pt_model as model\n",
    "import pt_helper as helper\n",
    "import pt_train as train\n",
    "\n",
    "# specify path to model parameters\n",
    "model_name = \"\"\n",
    "\n",
    "# specify dataset\n",
    "data_params = {\"dataset\":\"BLAT_ECOLX\"}\n",
    "\n",
    "# specify model params\n",
    "model_params = {\n",
    "    \"bs\"                :   100,\n",
    "    \"encode_dim_zero\"   :   1500,\n",
    "    \"encode_dim_one\"    :   1500,\n",
    "    \"decode_dim_zero\"   :   100,\n",
    "    \"decode_dim_one\"    :   500,\n",
    "    \"n_latent\"          :   30,\n",
    "    \"logit_p\"           :   0.001,\n",
    "    \"sparsity\"          :   \"logit\",\n",
    "    \"f_nonlin\"          :  \"sigmoid\",\n",
    "    \"fps\"               :   True,\n",
    "    \"n_pat\"             :   4,\n",
    "    \"r_seed\"            :   1,\n",
    "    \"conv_pat\"          :   True,\n",
    "    \"d_c_size\"          :   40,\n",
    "    \"sparsity_l\"        :   1.0,\n",
    "    \"l2_l\"              :   1.0,\n",
    "    \"dropout\"           :   True,\n",
    "    }\n",
    "\n",
    "def generate_spearmanr(mutant_name_list, delta_elbo_list, mutation_filename, phenotype_name):\n",
    "    \"\"\"\n",
    "    function that takes in mutant data from model and experimental data and prints a Spearman R correlation coefficient.\n",
    "    \"\"\"\n",
    "    measurement_df = pd.read_csv(mutation_filename, sep=',')\n",
    "\n",
    "    mutant_list = measurement_df.mutant.tolist()\n",
    "    expr_values_ref_list = measurement_df[phenotype_name].tolist()\n",
    "\n",
    "    mutant_name_to_pred = {mutant_name_list[i]: delta_elbo_list[i] for i in range(len(delta_elbo_list))}\n",
    "\n",
    "    # If there are measurements\n",
    "    wt_list = []\n",
    "    preds_for_spearmanr = []\n",
    "    measurements_for_spearmanr = []\n",
    "\n",
    "    for i, mutant_name in enumerate(mutant_list):\n",
    "        expr_val = expr_values_ref_list[i]\n",
    "\n",
    "        # Make sure we have made a prediction for that mutant\n",
    "        if mutant_name in mutant_name_to_pred:\n",
    "            multi_mut_name_list = mutant_name.split(':')\n",
    "\n",
    "            # If there is no measurement for that mutant, pass over it\n",
    "            if np.isnan(expr_val):\n",
    "                pass\n",
    "\n",
    "            # If it was a codon change, add it to the wt vals to average\n",
    "            elif mutant_name[0] == mutant_name[-1] and len(multi_mut_name_list) == 1:\n",
    "                wt_list.append(expr_values_ref_list[i])\n",
    "\n",
    "            # If it is labeled as the wt sequence, add it to the average list\n",
    "            elif mutant_name == 'wt' or mutant_name == 'WT':\n",
    "                wt_list.append(expr_values_ref_list[i])\n",
    "\n",
    "            else:\n",
    "                measurements_for_spearmanr.append(expr_val)\n",
    "                preds_for_spearmanr.append(mutant_name_to_pred[mutant_name])\n",
    "\n",
    "    if wt_list != []:\n",
    "        measurements_for_spearmanr.append(np.mean(wt_list))\n",
    "        preds_for_spearmanr.append(0.0)\n",
    "\n",
    "    num_data = len(measurements_for_spearmanr)\n",
    "    spearman_r, spearman_pval = ss.spearmanr(measurements_for_spearmanr, preds_for_spearmanr)\n",
    "    print(\"N: \" + str(num_data) + \", Spearmanr: \" + str(spearman_r) + \", p-val: \" + str(spearman_pval))\n",
    "\n",
    "# make datahelper and model\n",
    "data_helper = helper.DataHelper(dataset=data_params[\"dataset\"], working_dir=\".\", calc_weights=False)\n",
    "\n",
    "vae_model = model.VAE_MLE(data_helper,\n",
    "                             batch_size=model_params[\"bs\"],\n",
    "                             encoder_architecture=[model_params[\"encode_dim_zero\"],\n",
    "                                                   model_params[\"encode_dim_one\"]],\n",
    "                             decoder_architecture=[model_params[\"decode_dim_zero\"],\n",
    "                                                   model_params[\"decode_dim_one\"]],\n",
    "                             n_latent=model_params[\"n_latent\"],\n",
    "                             logit_p=model_params[\"logit_p\"],\n",
    "                             encode_nonlinearity_type=\"relu\",\n",
    "                             decode_nonlinearity_type=\"relu\",\n",
    "                             final_decode_nonlinearity=model_params[\"f_nonlin\"],\n",
    "                             final_pwm_scale=model_params[\"fps\"],\n",
    "                             conv_decoder_size=model_params[\"d_c_size\"],\n",
    "                             convolve_patterns=model_params[\"conv_pat\"],\n",
    "                             n_patterns=model_params[\"n_pat\"],\n",
    "                             random_seed=model_params[\"r_seed\"],\n",
    "                             sparsity_lambda=model_params[\"sparsity_l\"],\n",
    "                             l2_lambda=model_params[\"l2_l\"],\n",
    "                             sparsity=model_params[\"sparsity\"])\n",
    "\n",
    "print (\"Model built\")\n",
    "\n",
    "path = \"model_params/\"+model_name\n",
    "# load weights\n",
    "train.load(vae_model, path)\n",
    "print (\"Parameters loaded\\n\\n\")\n",
    "mutation = \"mutations/BLAT_ECOLX_Ranganathan2015.csv\" # path to experimental data\n",
    "\n",
    "# construct model's mutation predictions\n",
    "custom_mutant_name_list, custom_delta_elbos = data_helper.custom_mutant_matrix(mutation,\n",
    "                                                                               vae_model,\n",
    "                                                                               N_pred_iterations=500)\n",
    "\n",
    "# find Spearman R value\n",
    "generate_spearmanr(custom_mutant_name_list, custom_delta_elbos, mutation, \"2500\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
